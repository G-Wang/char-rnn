{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "\n",
    "train_data = unidecode.unidecode(open('sherlock.txt').read()) # load the text file, reading it\n",
    "vocab = string.printable # use all printable string characters as vocabulary\n",
    "vocab_length = len(vocab) # vocabulary length\n",
    "data_len = len(train_data) # get length of training data\n",
    "\n",
    "# utility function\n",
    "# get_batch utility function will randomly sample a batch of data of size k from a text corpus\n",
    "def get_batch(text_corpus, batch_size=100):\n",
    "    start = random.randint(0, data_len-batch_size)\n",
    "    end = start + batch_size + 1\n",
    "    return text_corpus[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, n_layers=1, rnn_type='gru'):\n",
    "        \"\"\"rnn class making\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._vocab_size = vocab_size # this is our vocabulary size, i.e 100\n",
    "        self._embedding_size = embedding_size # this is our embedding size, i.e the output size of embedding our sparse\n",
    "        # matrix, set at say 50\n",
    "        self._hidden_size = hidden_size # hidden size for the hidden rnn\n",
    "        self._n_layers = n_layers\n",
    "        \n",
    "        # create layers. If rnn_type is gru, use gru\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        if rnn_type == 'gru':\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, n_layers)\n",
    "        else:\n",
    "            raise NotImplementedError # this is to be implemented, for example replace with lstm\n",
    "        self.h2o = nn.Linear(hidden_size, vocab_size) # the hidden to output layer\n",
    "        self.softmax = nn.LogSoftmax() # numerically stable implementation of log of softmax. Need the log-softmax for\n",
    "        # computing the cross entropy log loss\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        \"\"\"given an x and a hidden h, forward pass through our network. Our final output should be a softmax prediction\n",
    "        over all the vocabulary.\n",
    "        \n",
    "        Args:\n",
    "            x: input of shape [seq_len] x will be a long tensor of size seq_len, essentially a list of integers ranging from\n",
    "            0 to 100, i.e x = [0, 5, 24, 0, 66]\n",
    "            h: h_0** of shape `(num_layers * num_directions, batch, hidden_size)`\n",
    "        \n",
    "        \"\"\"\n",
    "        seq_len = x.size()[0]\n",
    "        embed = self.embedding(x).view(seq_len, 1, -1) # rnn takes input of shape [seq_len x batch_size x input_dim]\n",
    "        rnn_out, hidden = self.rnn(embed, hidden)\n",
    "        return rnn_out\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self._n_layers, 1, self.hidden_size)\n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-225e5e0718f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-93c4f228696e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_size, embedding_size, hidden_size, n_layers, rnn_type)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrnn_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gru'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;31m# this is to be implemented, for example replace with lstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch0.4/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GRU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_layers'"
     ]
    }
   ],
   "source": [
    "net = RNN(100, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "for idx,word in enumerate(vocab):\n",
    "    word_to_idx[word] = idx\n",
    "    idx_to_word[idx] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 h\n"
     ]
    }
   ],
   "source": [
    "print(word_to_idx['h'], idx_to_word[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.GRU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.GRU(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(100,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = embed(torch.rand(100,100).long())\n",
    "\n",
    "out.shape\n",
    "\n",
    "nn.Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 'hello tofuboi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      " \n",
      "t\n",
      "o\n",
      "f\n",
      "u\n",
      "b\n",
      "o\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(g)):\n",
    "    print(g[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      " \n",
      "t\n",
      "o\n",
      "f\n",
      "u\n",
      "b\n",
      "o\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "for char in g:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 h\n",
      "1 e\n",
      "2 l\n",
      "3 l\n",
      "4 o\n",
      "5  \n",
      "6 t\n",
      "7 o\n",
      "8 f\n",
      "9 u\n",
      "10 b\n",
      "11 o\n",
      "12 i\n"
     ]
    }
   ],
   "source": [
    "for idx, char in enumerate(g):\n",
    "    print(idx,char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-0.4",
   "language": "python",
   "name": "pytorch0."
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
