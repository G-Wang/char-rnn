{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "\n",
    "train_data = unidecode.unidecode(open('sherlock.txt').read()) # load the text file, reading it\n",
    "vocab = string.printable # use all printable string characters as vocabulary\n",
    "vocab_length = len(vocab) # vocabulary length\n",
    "data_len = len(train_data) # get length of training data\n",
    "\n",
    "# utility function\n",
    "# get_batch utility function will randomly sample a batch of data of size k from a text corpus\n",
    "def get_batch(text_corpus, batch_size=100):\n",
    "    start = random.randint(0, data_len-batch_size)\n",
    "    end = start + batch_size + 1\n",
    "    return text_corpus[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, n_layers=1, rnn_type='gru'):\n",
    "        \"\"\"rnn class making\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._vocab_size = vocab_size # this is our vocabulary size, i.e 100\n",
    "        self._embedding_size = embedding_size # this is our embedding size, i.e the output size of embedding our sparse\n",
    "        # matrix, set at say 50\n",
    "        self._hidden_size = hidden_size # hidden size for the hidden rnn\n",
    "        self._n_layers = n_layers\n",
    "        \n",
    "        # create layers. If rnn_type is gru, use gru\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        if rnn_type == 'gru':\n",
    "            self.rnn = nn.GRU(embedding_size, hidden_size, n_layers)\n",
    "        else:\n",
    "            raise NotImplementedError # this is to be implemented, for example replace with lstm\n",
    "        self.h2o = nn.Linear(hidden_size, vocab_size) # the hidden to output layer\n",
    "        self.softmax = nn.LogSoftmax(dim=0) # numerically stable implementation of log of softmax. Need the log-softmax for\n",
    "        # computing the cross entropy log loss\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        \"\"\"given an x and a hidden h, forward pass through our network. Our final output should be a softmax prediction\n",
    "        over all the vocabulary.\n",
    "        \n",
    "        Args:\n",
    "            x: input of shape [seq_len] x will be a long tensor of size seq_len, essentially a list of integers ranging from\n",
    "            0 to 100, i.e x = [0, 5, 24, 0, 66]\n",
    "            h: h_0** of shape `(num_layers * num_directions, batch, hidden_size)`\n",
    "        \n",
    "        \"\"\"\n",
    "        # step 1, get sequence length\n",
    "        seq_len = x.size()[0]\n",
    "        # step 2. pass our input through our embedding layer, and get the output \"embed\", reshape it via view to get\n",
    "        # it ready for the rnn layer\n",
    "        embed = self.embedding(x).view(seq_len, 1, -1) # rnn takes input of shape [seq_len x batch_size x input_dim]\n",
    "        # step 3. forward pass our embed through our rnn layers, make sure to pass in hidden as well\n",
    "        rnn_out, hidden = self.rnn(embed, h) # compute the rnn output\n",
    "        # step 4: using our rnn output, pass it through the i2o(input to output) linear layer (remember to reshape to 2D)\n",
    "        # and get the non-normalized output prediction\n",
    "        prediction = self.h2o(rnn_out.view(seq_len,-1))\n",
    "        # step 5: normalize our prediction by taking the log_softmax\n",
    "        log_softmax = self.softmax(prediction)\n",
    "        # return log softmax prediction and hidden\n",
    "        return log_softmax, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self._n_layers, 1, self._hidden_size)\n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.7465, -4.5403, -4.6543,  ..., -4.6799, -4.7051, -4.6042],\n",
       "        [-4.6086, -4.5102, -4.4681,  ..., -4.7299, -4.6988, -4.5894],\n",
       "        [-4.6840, -4.5864, -4.6596,  ..., -4.5976, -4.5235, -4.4925],\n",
       "        ...,\n",
       "        [-4.6045, -4.6790, -4.5352,  ..., -4.6645, -4.6794, -4.6135],\n",
       "        [-4.7059, -4.6267, -4.7804,  ..., -4.6240, -4.9693, -4.2340],\n",
       "        [-4.7111, -4.7448, -4.5945,  ..., -4.6057, -4.8176, -4.4243]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# practice tests\n",
    "\n",
    "# step 1: create our network\n",
    "net = RNN(100, 100, 100)\n",
    "# step 2: create a training batch of data, size 101, format this data and convert it to pytorch long tensors\n",
    "dat = get_batch(train_data,100)\n",
    "dat = torch.LongTensor([vocab.find(item) for item in dat])\n",
    "# step 3: convert our dat into input/output\n",
    "ho = net.init_hidden()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([191, 1, 100])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "for idx,word in enumerate(vocab):\n",
    "    word_to_idx[word] = idx\n",
    "    idx_to_word[idx] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 h\n"
     ]
    }
   ],
   "source": [
    "print(word_to_idx['h'], idx_to_word[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.GRU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.GRU(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "output, hn = rnn(input, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(100,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = embed(torch.rand(100,100).long())\n",
    "\n",
    "out.shape\n",
    "\n",
    "nn.Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 'hello tofuboi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      " \n",
      "t\n",
      "o\n",
      "f\n",
      "u\n",
      "b\n",
      "o\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(g)):\n",
    "    print(g[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      " \n",
      "t\n",
      "o\n",
      "f\n",
      "u\n",
      "b\n",
      "o\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "for char in g:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 h\n",
      "1 e\n",
      "2 l\n",
      "3 l\n",
      "4 o\n",
      "5  \n",
      "6 t\n",
      "7 o\n",
      "8 f\n",
      "9 u\n",
      "10 b\n",
      "11 o\n",
      "12 i\n"
     ]
    }
   ],
   "source": [
    "for idx, char in enumerate(g):\n",
    "    print(idx,char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-0.4",
   "language": "python",
   "name": "pytorch0.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
